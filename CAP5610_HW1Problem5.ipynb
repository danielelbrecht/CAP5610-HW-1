{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAP5610_HW1Problem5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielelbrecht/CAP5610-HW-1/blob/master/CAP5610_HW1Problem5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "u_uQh4L3753M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#Load data\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oxlUYK6obzHx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Softmax classifier using Keras.  Additional features added to quantify images"
      ]
    },
    {
      "metadata": {
        "id": "QxlUP_iJ789W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Preprocess data\n",
        "train_images = train_images_original.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images_original.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z0DeeP-38RfY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Define hyperparameters\n",
        "learning_rate = 0.01\n",
        "epochs = 10\n",
        "classes = 10\n",
        "batch_size = 100\n",
        "\n",
        "#Use one-hot encoding\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels_original)\n",
        "test_labels = to_categorical(test_labels_original)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PSsjCf85b8n3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Function to calculate connected components in an image\n",
        "\n",
        "  \n",
        "#Connected components\n",
        "def get_connected_components(image):\n",
        "  \n",
        "  n = 0\n",
        "  labels = np.zeros(shape = (28, 28))\n",
        "  \n",
        "  \n",
        "  #Assign a label to each pixel in image\n",
        "  for i in range(28):\n",
        "    for j in range(28):\n",
        "      \n",
        "      #If pixel is unlabeled, find every connected pixel and mark them as explored\n",
        "      if labels[i][j] == 0 and image[i][j] == 0:\n",
        "        \n",
        "        n = n + 1\n",
        "        x, y = i, j\n",
        "        stack = [[i, j]]\n",
        "        explored = []\n",
        "        \n",
        "        \n",
        "        while stack != []:\n",
        "          \n",
        "          #get neighbors\n",
        "          if [x,max(0,y-1)] not in explored and image[x][max(0,y-1)] == 0:\n",
        "            stack.append([x,max(0,y-1)])\n",
        "          if [x,min(27, y+1)] not in explored and image[x][min(27, y+1)] == 0:\n",
        "            stack.append([x,min(27, y+1)])\n",
        "          if [max(0, x-1),y] not in explored and image[max(0,x-1)][y] == 0:\n",
        "            stack.append([max(0,x-1),y])\n",
        "          if [min(27, x+1),y] not in explored and image[min(27, x+1)][y] == 0:\n",
        "            stack.append([min(27, x+1),y])\n",
        "          \n",
        "          \n",
        "          #Label pixel being popped from stack\n",
        "          labels[x][y] = 1\n",
        "          \n",
        "          #Do updates\n",
        "          temp = stack.pop()\n",
        "          x = temp[0]\n",
        "          y = temp[1]\n",
        "          explored.append(temp)\n",
        "          \n",
        "          \n",
        "        \n",
        "  return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IcA8iT4bpmRp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "for i in range(1000):\n",
        "  print(\"Connected components: \", get_connected_components(train_images_original[i]))\n",
        "  print('Digit', train_labels_original[i])\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SXO6AoBHyLu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        },
        "outputId": "ef39ac17-f2e4-46eb-9a36-982eb6d61725"
      },
      "cell_type": "code",
      "source": [
        "#Modify data to include new features\n",
        "\n",
        "train_images_modified = []\n",
        "\n",
        "for i in range(len(train_images)):\n",
        "  train_images_modified.append(np.append(train_images[i], get_connected_components(train_images_original[i])))\n",
        "  \n",
        "  if i % 1000 == 0:\n",
        "    print(i ,\"examples trained\")\n",
        "                                 \n",
        "                                 \n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 examples traines\n",
            "1000 examples traines\n",
            "2000 examples traines\n",
            "3000 examples traines\n",
            "4000 examples traines\n",
            "5000 examples traines\n",
            "6000 examples traines\n",
            "7000 examples traines\n",
            "8000 examples traines\n",
            "9000 examples traines\n",
            "10000 examples traines\n",
            "11000 examples traines\n",
            "12000 examples traines\n",
            "13000 examples traines\n",
            "14000 examples traines\n",
            "15000 examples traines\n",
            "16000 examples traines\n",
            "17000 examples traines\n",
            "18000 examples traines\n",
            "19000 examples traines\n",
            "20000 examples traines\n",
            "21000 examples traines\n",
            "22000 examples traines\n",
            "23000 examples traines\n",
            "24000 examples traines\n",
            "25000 examples traines\n",
            "26000 examples traines\n",
            "27000 examples traines\n",
            "28000 examples traines\n",
            "29000 examples traines\n",
            "30000 examples traines\n",
            "31000 examples traines\n",
            "32000 examples traines\n",
            "33000 examples traines\n",
            "34000 examples traines\n",
            "35000 examples traines\n",
            "36000 examples traines\n",
            "37000 examples traines\n",
            "38000 examples traines\n",
            "39000 examples traines\n",
            "40000 examples traines\n",
            "41000 examples traines\n",
            "42000 examples traines\n",
            "43000 examples traines\n",
            "44000 examples traines\n",
            "45000 examples traines\n",
            "46000 examples traines\n",
            "47000 examples traines\n",
            "48000 examples traines\n",
            "49000 examples traines\n",
            "50000 examples traines\n",
            "51000 examples traines\n",
            "52000 examples traines\n",
            "53000 examples traines\n",
            "54000 examples traines\n",
            "55000 examples traines\n",
            "56000 examples traines\n",
            "57000 examples traines\n",
            "58000 examples traines\n",
            "59000 examples traines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3AJp2cIc8WBY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Define model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(layers.Dense(classes, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = tf.train.AdamOptimizer(learning_rate),\n",
        "                            loss = 'categorical_crossentropy',\n",
        "                            metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xwVhFd_V8j6Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training\n",
        "\n",
        "model.fit(train_images_modified, train_labels, epochs = epochs, batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}